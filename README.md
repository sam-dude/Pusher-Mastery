# Pusher Mastery - Notebook-Based Structure
This is a deep dive into robotic manipulation using Reinforcement Learning. In this experiment I learn to try different deep learning algorithm for Pusher environment provided by Gymnasium

## Getting Started
1. Activate environment: \`source pusher_env/bin/activate\`
2. Launch Jupyter: \`jupyter lab\`
3. Open \`notebooks/00_setup_and_test.ipynb\`


## ğŸ“ Project Layout

```
pusher_mastery/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”‚
â”œâ”€â”€ notebooks/                          # Main learning happens here
â”‚   â”œâ”€â”€ 00_setup_and_test.ipynb       # Environment setup
â”‚   â”œâ”€â”€ 01_environment_exploration.ipynb
â”‚   â”œâ”€â”€ 02_heuristic_policy.ipynb
â”‚   â”œâ”€â”€ 03_sac_implementation.ipynb
â”‚   â”œâ”€â”€ 04_sac_training.ipynb
â”‚   â”œâ”€â”€ 05_reward_engineering.ipynb
â”‚   â”œâ”€â”€ 06_curriculum_learning.ipynb
â”‚   â”œâ”€â”€ 07_algorithm_comparison.ipynb
â”‚   â””â”€â”€ 08_analysis_and_visualization.ipynb
â”‚
â”œâ”€â”€ src/                                # Clean implementations
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ sac.py                     # Extracted from notebook
â”‚   â”‚   â”œâ”€â”€ td3.py
â”‚   â”‚   â””â”€â”€ ppo.py
â”‚   â”œâ”€â”€ environments/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ wrappers.py                # Custom env wrappers
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ visualization.py
â”‚       â”œâ”€â”€ logging.py
â”‚       â””â”€â”€ replay_buffer.py
â”‚
â”œâ”€â”€ scripts/                            # Standalone scripts
â”‚   â”œâ”€â”€ train_sac.py                   # For long training runs
â”‚   â”œâ”€â”€ train_td3.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ create_videos.py
â”‚
â”œâ”€â”€ results/                            # Saved results
â”‚   â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ videos/
â”‚   â”œâ”€â”€ logs/
â”‚   â””â”€â”€ tables/
â”‚
â”œâ”€â”€ checkpoints/                        # Model checkpoints
â”‚   â”œâ”€â”€ sac/
â”‚   â”œâ”€â”€ td3/
â”‚   â””â”€â”€ ppo/
â”‚
â”œâ”€â”€ docs/                               # Documentation
â”‚   â”œâ”€â”€ lessons_learned.md
â”‚   â”œâ”€â”€ troubleshooting.md
â”‚   â””â”€â”€ blog_drafts/
â”‚
â””â”€â”€ data/                               # Saved datasets
    â””â”€â”€ demonstrations/
```


## Notebooks Overview

1. **00_setup_and_test.ipynb** - Verify installation
2. **01_environment_exploration.ipynb** - Understand Pusher
3. **02_heuristic_policy.ipynb** - Build baseline
4. **03_sac_implementation.ipynb** - Implement SAC
5. **04_sac_training.ipynb** - Train agent
6. **05_reward_engineering.ipynb** - Optimize rewards
7. **06_curriculum_learning.ipynb** - Speed up learning
8. **07_algorithm_comparison.ipynb** - Compare algorithms
9. **08_analysis_and_visualization.ipynb** - Deep analysis

## Author

Samuel Ibiyemi

## License

MIT
